{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58786a26-e70d-46fe-92d0-0fcdb2bd87d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tokenizers in /home/jupyter/.local/lib/python3.10/site-packages (0.20.0)\n",
      "Requirement already satisfied: datasets in /home/jupyter/.local/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: evaluate in /home/jupyter/.local/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: accelerate in /home/jupyter/.local/lib/python3.10/site-packages (0.34.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/jupyter/.local/lib/python3.10/site-packages (from tokenizers) (0.25.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.12.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/jupyter/.local/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/jupyter/.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/jupyter/.local/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/jupyter/.local/lib/python3.10/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /home/jupyter/.local/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/jupyter/.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /home/jupyter/.local/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /home/jupyter/.local/lib/python3.10/site-packages (from datasets) (3.10.9)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: psutil in /kernel/lib/python3.10/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/jupyter/.local/lib/python3.10/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/jupyter/.local/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/jupyter/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.13.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install tokenizers datasets evaluate accelerate torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaa00ba4-1f31-4a7e-ab14-8f9826d00a9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T11:16:56.340819Z",
     "iopub.status.busy": "2024-10-06T11:16:56.339874Z",
     "iopub.status.idle": "2024-10-06T11:16:58.790764Z",
     "shell.execute_reply": "2024-10-06T11:16:58.789976Z",
     "shell.execute_reply.started": "2024-10-06T11:16:56.340777Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/jupyter/.local/lib/python3.10/site-packages (4.45.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /home/jupyter/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jupyter/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8b659d1-aa10-41ba-aed7-f8b38450012d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T13:50:17.542762Z",
     "iopub.status.busy": "2024-10-06T13:50:17.541753Z",
     "iopub.status.idle": "2024-10-06T13:50:26.613281Z",
     "shell.execute_reply": "2024-10-06T13:50:26.612506Z",
     "shell.execute_reply.started": "2024-10-06T13:50:17.542717Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caae372-a9e3-4a17-b818-e7927049d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "DATA_DIR = '/home/jupyter/datasphere/project/MovieReview/Users/daniil/Desktop/University/AI/GreenAtom/aclImdb'\n",
    "\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, texts, ratings, sentiments, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.ratings = ratings\n",
    "        self.sentiments = sentiments\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        rating = self.ratings[idx]\n",
    "        sentiment = self.sentiments[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'rating': torch.tensor(rating, dtype=torch.long),\n",
    "            'sentiment': torch.tensor(sentiment, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "\n",
    "def load_data(data_dir, split):\n",
    "    texts = []\n",
    "    ratings = []\n",
    "    sentiments = []\n",
    "\n",
    "    for label in ['pos', 'neg']:\n",
    "        sentiment = 1 if label == 'pos' else 0\n",
    "        dir_path = os.path.join(data_dir, split, label)\n",
    "        for filename in os.listdir(dir_path):\n",
    "            if filename.endswith('.txt') and not(filename.startswith('._')):\n",
    "                rating = int(filename.split('_')[1].split('.')[0])\n",
    "                if rating < 0 or rating > 10:\n",
    "                    print(filename)\n",
    "                with open(os.path.join(dir_path, filename), 'r', encoding='latin-1') as f:\n",
    "                    text = f.read()\n",
    "                    texts.append(text)\n",
    "                    ratings.append(rating)\n",
    "                    sentiments.append(sentiment)\n",
    "    return texts, ratings, sentiments\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 96\n",
    "\n",
    "train_texts, train_ratings, train_sentiments = load_data(DATA_DIR, 'train')\n",
    "test_texts, test_ratings, test_sentiments = load_data(DATA_DIR, 'test')\n",
    "\n",
    "train_dataset = IMDBDataset(train_texts, train_ratings, train_sentiments, tokenizer, MAX_LENGTH)\n",
    "test_dataset = IMDBDataset(test_texts, test_ratings, test_sentiments, tokenizer, MAX_LENGTH)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "class SentimentRatingModel(nn.Module):\n",
    "    def __init__(self, n_ratings):\n",
    "        super(SentimentRatingModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.sentiment_classifier = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "        self.rating_classifier = nn.Linear(self.bert.config.hidden_size, n_ratings)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        sentiment_logits = self.sentiment_classifier(pooled_output)\n",
    "        rating_logits = self.rating_classifier(pooled_output)\n",
    "        return sentiment_logits, rating_logits\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    model = SentimentRatingModel(n_ratings=10)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "    criterion_sentiment = nn.CrossEntropyLoss()\n",
    "    criterion_rating = nn.CrossEntropyLoss()\n",
    "\n",
    "    torch.save(model.state_dict(), 'sentiment_rating_model.pth')\n",
    "\n",
    "    EPOCHS = 3\n",
    "    save_interval = 100  \n",
    "    batch_count = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            batch_count += 1\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            sentiments = batch['sentiment'].to(device)\n",
    "            ratings = batch['rating'].to(device) - 1  \n",
    "\n",
    "            sentiment_logits, rating_logits = model(input_ids, attention_mask)\n",
    "\n",
    "            loss_sentiment = criterion_sentiment(sentiment_logits, sentiments)\n",
    "            loss_rating = criterion_rating(rating_logits, ratings)\n",
    "\n",
    "            loss = loss_sentiment + loss_rating\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_count % save_interval == 0:\n",
    "                torch.save(model.state_dict(), 'sentiment_rating_model.pth')\n",
    "                print(f'Сохранение модели после {batch_count} batch\\'ей')\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Эпоха {epoch + 1}/{EPOCHS}, Потеря: {avg_loss:.4f}')\n",
    "\n",
    "        torch.save(model.state_dict(), 'sentiment_rating_model.pth')\n",
    "        print(f'Модель сохранена после эпохи {epoch + 1}')\n",
    "\n",
    "    model.eval()\n",
    "    correct_sentiment = 0\n",
    "    correct_rating = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            sentiments = batch['sentiment'].to(device)\n",
    "            ratings = batch['rating'].to(device) - 1 \n",
    "\n",
    "            sentiment_logits, rating_logits = model(input_ids, attention_mask)\n",
    "\n",
    "            _, sentiment_preds = torch.max(sentiment_logits, dim=1)\n",
    "            _, rating_preds = torch.max(rating_logits, dim=1)\n",
    "\n",
    "            correct_sentiment += (sentiment_preds == sentiments).sum().item()\n",
    "            correct_rating += (rating_preds == ratings).sum().item()\n",
    "            total += sentiments.size(0)\n",
    "\n",
    "    print(f'Точность тональности: {correct_sentiment / total * 100:.2f}%')\n",
    "    print(f'Точность рейтинга: {correct_rating / total * 100:.2f}%')\n",
    "\n",
    "    torch.save(model.state_dict(), 'sentiment_rating_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
