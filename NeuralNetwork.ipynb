{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36f738b6-918a-4c49-a10a-09a39148c608",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T21:24:17.805379Z",
     "iopub.status.busy": "2024-10-17T21:24:17.804073Z",
     "iopub.status.idle": "2024-10-17T21:37:02.716929Z",
     "shell.execute_reply": "2024-10-17T21:37:02.715733Z",
     "shell.execute_reply.started": "2024-10-17T21:24:17.805340Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1/5: 100%|██████████| 1563/1563 [02:05<00:00, 12.49it/s, Потеря=1.2772] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря за эпоху: 11.0779\n",
      "Модель сохранена после эпохи 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 2/5: 100%|██████████| 1563/1563 [02:07<00:00, 12.28it/s, Потеря=9.3936] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря за эпоху: 3.4132\n",
      "Модель сохранена после эпохи 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 3/5: 100%|██████████| 1563/1563 [02:07<00:00, 12.26it/s, Потеря=1.3217] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря за эпоху: 2.0853\n",
      "Модель сохранена после эпохи 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 4/5: 100%|██████████| 1563/1563 [02:06<00:00, 12.35it/s, Потеря=1.1323]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря за эпоху: 1.4769\n",
      "Модель сохранена после эпохи 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 5/5: 100%|██████████| 1563/1563 [02:03<00:00, 12.64it/s, Потеря=0.4016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря за эпоху: 1.1727\n",
      "Модель сохранена после эпохи 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Оценка: 100%|██████████| 1563/1563 [01:06<00:00, 23.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность тональности: 89.03%\n",
      "Средняя абсолютная ошибка рейтинга: 1.28\n",
      "Финальная модель успешно сохранена.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "DATA_DIR = '/home/jupyter/datasphere/project/MovieReview/Users/daniil/Desktop/University/AI/GreenAtom/aclImdb'\n",
    "\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, texts, ratings, sentiments, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.ratings = ratings\n",
    "        self.sentiments = sentiments\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        rating = self.ratings[idx]\n",
    "        sentiment = self.sentiments[idx]\n",
    "\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'rating': torch.tensor(rating, dtype=torch.float),\n",
    "            'sentiment': torch.tensor(sentiment, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "\n",
    "def load_data(data_dir, split):\n",
    "    texts = []\n",
    "    ratings = []\n",
    "    sentiments = []\n",
    "\n",
    "    for label in ['pos', 'neg']:\n",
    "        sentiment = 1 if label == 'pos' else 0\n",
    "        dir_path = os.path.join(data_dir, split, label)\n",
    "        for filename in os.listdir(dir_path):\n",
    "            if filename.endswith('.txt') and not filename.startswith('._'):\n",
    "\n",
    "                rating = int(filename.split('_')[1].split('.')[0])\n",
    "\n",
    "                if rating == 5 or rating == 6:\n",
    "                    continue\n",
    "                with open(os.path.join(dir_path, filename), 'r', encoding='utf-8') as f:\n",
    "                    text = f.read()\n",
    "                    texts.append(text)\n",
    "                    ratings.append(rating)\n",
    "                    sentiments.append(sentiment)\n",
    "    return texts, ratings, sentiments\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "MAX_LENGTH = 128  \n",
    "BATCH_SIZE = 16  \n",
    "\n",
    "train_texts, train_ratings, train_sentiments = load_data(DATA_DIR, 'train')\n",
    "test_texts, test_ratings, test_sentiments = load_data(DATA_DIR, 'test')\n",
    "\n",
    "train_dataset = IMDBDataset(train_texts, train_ratings, train_sentiments, tokenizer, MAX_LENGTH)\n",
    "test_dataset = IMDBDataset(test_texts, test_ratings, test_sentiments, tokenizer, MAX_LENGTH)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "class SentimentRatingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SentimentRatingModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "        self.sentiment_classifier = nn.Sequential(\n",
    "            nn.Linear(self.bert.config.hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "        self.rating_regressor = nn.Sequential(\n",
    "            nn.Linear(self.bert.config.hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output \n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "        sentiment_logits = self.sentiment_classifier(pooled_output)\n",
    "\n",
    "        rating_output = self.rating_regressor(pooled_output).squeeze(-1)\n",
    "        return sentiment_logits, rating_output\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    model = SentimentRatingModel()\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion_sentiment = nn.CrossEntropyLoss()\n",
    "    criterion_rating = nn.MSELoss()\n",
    "\n",
    "\n",
    "    EPOCHS = 5  \n",
    "    total_steps = len(train_loader) * EPOCHS\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f'Эпоха {epoch + 1}/{EPOCHS}')\n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "            sentiments = batch['sentiment'].to(device, non_blocking=True)\n",
    "            ratings = batch['rating'].to(device, non_blocking=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                sentiment_logits, rating_output = model(input_ids, attention_mask)\n",
    "                loss_sentiment = criterion_sentiment(sentiment_logits, sentiments)\n",
    "                loss_rating = criterion_rating(rating_output, ratings)\n",
    "                loss = loss_sentiment + loss_rating\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({'Потеря': f'{loss.item():.4f}'})\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Средняя потеря за эпоху: {avg_loss:.4f}')\n",
    "\n",
    "\n",
    "        torch.save(model.state_dict(), f'sentiment_rating_model_epoch_FORM1_{epoch + 1}.pth')\n",
    "        print(f'Модель сохранена после эпохи {epoch + 1}')\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    correct_sentiment = 0\n",
    "    total_sentiment = 0\n",
    "    rating_errors = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc='Оценка'):\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "            sentiments = batch['sentiment'].to(device, non_blocking=True)\n",
    "            ratings = batch['rating'].to(device, non_blocking=True)\n",
    "\n",
    "            sentiment_logits, rating_output = model(input_ids, attention_mask)\n",
    "\n",
    "            _, sentiment_preds = torch.max(sentiment_logits, dim=1)\n",
    "\n",
    "            correct_sentiment += (sentiment_preds == sentiments).sum().item()\n",
    "            total_sentiment += sentiments.size(0)\n",
    "\n",
    "\n",
    "            rating_errors.extend(torch.abs(rating_output - ratings).cpu().numpy())\n",
    "\n",
    "    sentiment_accuracy = correct_sentiment / total_sentiment * 100\n",
    "    rating_mae = sum(rating_errors) / len(rating_errors)\n",
    "\n",
    "    print(f'Точность тональности: {sentiment_accuracy:.2f}%')\n",
    "    print(f'Средняя абсолютная ошибка рейтинга: {rating_mae:.2f}')\n",
    "\n",
    "\n",
    "    torch.save(model.state_dict(), 'sentiment_rating_model_final.pth')\n",
    "    print(\"Финальная модель успешно сохранена.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
